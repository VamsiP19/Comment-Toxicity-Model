# Comment-Toxicity-Model
This repository houses a deep learning model designed to identify and classify toxic comments within online platforms. By employing Natural Language Processing (NLP) techniques, the model effectively detects various forms of toxicity, including toxic, severe toxic, obscene, threat, insult, identity hate.

Key Features:

Accurate Toxicity Detection: Precisely identifies toxic comments with high precision and recall.
Multi-Label Classification: Categorizes comments into multiple toxicity types simultaneously.
Robust Model Architecture: Employs a neural network architecture for optimal performance.
Potential Applications:

Social Media Platforms: Improves community safety and fosters positive online interactions.
Online Forums: Creates a more inclusive and respectful environment for discussions.
Customer Support: Identifies and addresses toxic customer interactions.

The video of the final project:

https://github.com/user-attachments/assets/054f20d2-30e4-4127-8c22-2074692db7bc


The RNN model is given below:


<img width="457" alt="Screenshot 2024-08-18 at 7 59 04â€¯PM" src="https://github.com/user-attachments/assets/ac2a1d3f-9efa-41a0-84b0-7644de076e58">
